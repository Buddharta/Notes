\documentclass[main.tex]{subfiles}
\begin{document}
\chapter{Teor'ia de Sturm-Liouville}
\noindent Si recordamos la motivaci'on para el estudio de las series de Fourier, intentamos encontrar soluciones generales para la \emph{ecuación de Schrödinger en una dimensión} con potencial \(V(x)\) \emph{independiente del tiempo}. Para resolverla utilizamos el \emph{método de separación de variables o método de Bernoulli}, el cual divide el problema en dos ecuaciones,

\begin{enumerate}
    \item \textbf{Ecuación Temporal}:
    \[
    i\hbar \dfrac{d \phi(t)}{dt} = E \phi(t).
    \]
    Cuya solución es
    \[
    \phi(t) = \phi(0) e^{-iEt/\hbar}.
    \]

    \item \textbf{Ecuación Espacial}:
    \[
    -\frac{\hbar^2}{2m} \dfrac{d^2 \varphi(x)}{dx^2} + V(x) \varphi(x) = E \varphi(x).
    \]
    La cual define el \emph{operador hamiltoniano cuántico}
    \[
    H =-\frac{\hbar^2}{2m} \dfrac{d^2 }{dx^2} + V(x)I,
    \]
    además \(E\) representa la energía del estado estacionario, la energía cumplen con una ecuación del tipo
    \[
    H\varphi=E\varphi,
    \]
    también conocida como ecuación de vectores propios o \emph{ecuación espectral}.
\end{enumerate}
La ecuaci'on  espectral para el operador hamiltoniano con un potencial independiente del tiempo, es es el tipo de ecuaciones y el tipo de operadores que estudiaremos en esta secci'on, estos operadores son conocidos como los operadores de \emph{Sturm-Liouville}. Estos operadores provienen de manera natural de la resoluci'on de ecuaciones diferenciales parcialers con ciertas condiciones de frontera, de la misma forma que cuando resolvimos la ecuaci'on de Schrödinger. El nombre de esta teor'ia y operadores proviene de los matem'aticos \emph{Jaques Sturm} y \emph{Joseph Liouville} quienes estudiaron este tipo de ecuaciones en el siglo XIX.

\begin{def.}{Operadores de Sturm-Liouville}
  Sean \(p(x)\) y \(q(x)\)son funciones dadas, se define \(\mathcal{L}\) el operador de Sturm-Liouville como
  \[
    \mathcal{L}= -\frac{d}{dx} \left( p(x) \dfrac{d}{dx} \right) + q(x)I.
  \]
  Ahora, estudiaremos el caso cuando \(\phi(x)\) es una función propia y \(\lambda\) es el valor propio asociado con un peso \(w(x)\), es decir la ecuaci'on
  \[
    \mathcal{L}\phi(x)= -\frac{d}{dx}\left( p(x) \dfrac{d\phi}{dx}(x)\right) + q(x)\phi(x)=\lambda w(x)\phi(x).
  \]
\end{def.}
\section{Ecuaciones diferenciales lineales de orden dos.}
\noindent Comenzamos con un repaso de ecuaciones diferenciales ordinarias de orden dos, as'i, cc consideramos la ecuación diferencial ordinaria de segundo orden en el intervalo real \( I \), dada por
\[
a_0(x)y''+a_1(x)y'+a_2(x)y= f(x),
\]
donde \(a_0\), \(a_1\), \(a_2\) y \(f\) son funciones complejas definidas en \(I\). Cuando \(f\equiv 0\) en \(I\), la ecuación se llama \textbf{homogénea}; de lo contrario, se llama \textbf{no homogénea}. Cualquier función (compleja) \(\phi \in C^2(I)\) es una solución de la ecuación si la sustitución de \(y\) por \(\phi\) resulta en la identidad

\[
a_0(x)\phi''(x)+a_1(x)\phi'(x)+a_2(x)\phi(x)=f(x) \quad \text{para todo }x\in I.
\]

Si denotamos el operador diferencial de segundo orden

\[
L=a_0(x)\frac{d^2}{dx^2}+a_1(x)\frac{d}{dx}+a_2(x)I,
\]

entonces la ecuaci'on la escribimos la forma \(Ly= f\). El operador \(L\) es lineal, es decir,
\[
L(c_1\phi+c_2\psi)=c_1L\phi+c_2 L\psi\quad\forall\phi,\psi \in C^2(I),\,c_1,c_2\in\co
\]

De igual manera si

\[
L\phi = 0, \quad L\psi=0,
\]

entonces

\[
L(c_1\phi+c_2\psi)=c_1L\phi+c_2L\psi=0,
\]

para cualquier par de constantes \(c_1\) y \(c_2\). Esto se conoce como el \textbf{principio de superposición}.
Si la función \(a_0\) no se anula en ningún punto de \(I\), la ecuación puede dividirse por \(a_0\) para obtener
\[
y'' + p(x) y' + q(x) y = g(x),\quad p(x)=\frac{a_1(x)}{a_0(x)},\,q(x)=\frac{a_2(x)}{a_0(x)},\,g(x)=\frac{f(x)}{a_0(x)}.
\]
Claramente ambas ecuaciones son equivalentes, en el sentido de que tienen el mismo conjunto de soluciones. La ecuación se dice entonces \textbf{regular} en \(I\); de lo contrario, si existe un punto \(c\in I\) donde \(a_0(c)=0\), la ecuación es \textbf{singular}, y \(c\) se denomina \textbf{punto singular} de la ecuación.

De acuerdo con el teorema de existencia y unicidad para ecuaciones lineales, si las funciones \(q\), \(r\) y \(g\) son continuas en \(I\) y \(x_0\) es un punto en \(I\), entonces, para cualesquiera dos números \(\xi\) y \(\eta\), existe una única solución \(\phi\) en \(I\) tal que
\[
\phi(x_0) = \xi, \quad \phi'(x_0) = \eta.
\]

A continuación, enumeramos algunas propiedades bien conocidas de las soluciones de la ecuación, que pueden encontrarse en muchas introducciones estándar a las ecuaciones diferenciales ordinarias.

\begin{enumerate}
    \item La ecuación homogénea
    \[
    y''+p(x)y'+q(x)y=0,\quad x\in I,
    \]
    tiene dos soluciones linealmente independientes \(y_1(x)\) y \(y_2(x)\) en \(I\). Una combinación lineal de estas dos soluciones
    \[
    c_1y_1+c_2y_2,
    \]
    donde \(c_1\) y \(c_2\) son constantes arbitrarias, es la \textbf{solución general}; es decir, cualquier solución de la ecuación está dada por esta combinaci'on para algunos valores de \(c_1\) y \(c_2\). Cuando \(c_1=c_2=0\), obtenemos la llamada \textbf{solución trivial} la cual, siempre es una solución de la ecuación homogénea. Por el teorema de unicidad, es la única solución si \(\xi=\eta=0\).

    \item Si \(y_p(x)\) es cualquier solución particular de la ecuación no homogénea, entonces
    \[
    y_p+c_1y_1+c_2y_2
    \]
    es la solución general de la ecuaci'on no homogenea. Aplicando las condiciones iniciales, las constantes \(c_1\) y \(c_2\) se determinan y obtenemos la solución única del sistema de ecuaciones.

    \item Cuando los coeficientes \(p\) y \(q\) son constantes, la solución general de la ecuación tiene la forma
    \[
    y(x)=c_1 e^{m_1 x} + c_2 e^{m_2 x},
    \]
    donde \(m_1\) y \(m_2\) son las raíces del polinomio caracter'istico \(m^2+pm+q=0\) cuando las raíces son distintas. Si \(m_1=m_2=m\), entonces por variaci'on de par'ametros, la solución toma la forma
    \[
    y(x)=c_1 e^{m x}+c_2xe^{m x},
    \]
    donde las funciones \(e^{mx}\) y \(xe^{mx}\) son claramente linealmente independientes.

    \item Cuando \(a_0(x)=x^2\), \(a_1(x)=ax\) y \(a_2(x)=b\), donde \(a\) y \(b\) son constantes, la versión homogénea de la ecuación se convierte en
    \[
    x^2y''+axy'+by=0,
    \]
    que se llama la \textbf{ecuación de Cauchy-Euler}, su solución general está dada por
    \[
    y(x)=c_1 x^{m_1}+c_2 x^{m_2},
    \]
    donde \(m_1\) y \(m_2\) son las raíces distintas de \(m^2+(a-1)m+b=0\). De igual manera usando variaci'on de par'ametros, cuando \(m_1=m_2=m\), la solución es
    \[
    y(x)=c_1 x^m+c_2x^m\log x.
    \]

    \item El \emph{teorema de Cauchy-Kovaleskaya} asegura que si los coeficientes \(q(x)\) y \(r(x)\) son funciones analíticas en algún punto \(x_0\) en el interior de \(I\), es decir, cada uno puede representarse en un intervalo abierto centrado en \(x_0\) por una serie de potencias en \((x-x_0)\), entonces la solución general también es analítica en \(x_0\) y se representa por una serie de potencias de la forma
    \[
    y(x)=\sum_{n=0}^\infty c_n (x - x_0)^n\text{ alrededor de }x_{0}.
    \]
    La serie converge en la intersección de los dos intervalos de convergencia (de \(q(x)\) y \(r(x)\)) e \(I\). El \emph{m'etodo de Frobenius} nos dice que si sustituimos esta serie en la ecuación, podemos expresar los coeficientes \(c_n\), para todo \(n\in\{2, 3, 4,\dots\}\), en términos de \(c_0\) y \(c_1\), que permanecen arbitrarios, veremos m'as de esto cuando veamos las \emph{funciones de Bessel}.
\end{enumerate}

Con \(I=[a,b]\), las soluciones de la ecuación pueden estar sujetas a condiciones de frontera en \(a\) y \(b\). Estas pueden tomar una de las siguientes formas

\begin{enumerate}
    \item[(i)] \(y(c)=\xi\), \(y'(c)=\eta\), \(c\in\{a,b\}\),
    \item[(ii)] \(y(a)=\xi\), \(y(b)=\eta\),
    \item[(iii)] \(y'(a)=\xi\), \(y'(b)=\eta\).
\end{enumerate}

Cuando las condiciones de frontera se dan en el mismo punto \(c\), como en \((i)\), a menudo se denominan \textbf{condiciones iniciales}, como se mencionó anteriormente. Para obtener una solución única de la ecuación, el punto \(c\) no necesita, en general, ser uno de los extremos del intervalo \(I\), y puede ser cualquier punto interior. Pero en esta presentación, como en la mayoría de las aplicaciones físicas, las condiciones de contorno (o iniciales) siempre se imponen en los extremos de \(I\). Las formas \((i)\) a \((iii)\) de las condiciones de contorno pueden generalizarse mediante el par de ecuaciones

\begin{align*}
&\alpha_1 y(a)+\alpha_2 y'(a)+\alpha_3y(b)+\alpha_4y'(b)=\xi,\\
&\beta_1 y(b)+\beta_2y'(b)+\beta_3y(a)+\beta_4y'(a)=\eta,
\end{align*}

donde \(\alpha_i\) y \(\beta_i\) son constantes que satisfacen \(\sum_{i=1}^4|\alpha_i|>0\) y \(\sum_{i=1}^4|\beta_i|>0\), es decir, tales que no todos los \(\alpha_i\) o \(\beta_i\) son cero. El sistema de ecuaciones anterior se llama un \textbf{problema de valores de frontera}.

Las condiciones de frontera se llaman \textbf{homogéneas} si \(\xi=\eta=0\), y \textbf{separadas} si \(\alpha_3=\alpha_4=\beta_3=\beta_4=0\). Las condiciones de frontera separadas, que tienen la forma

\[
\alpha_1y(a)+\alpha_2y'(a)=\xi,\quad\beta_1y(b)+\beta_2y'(b)=\eta,
\]

son de particular importancia en este estudio. Otro par importante de condiciones homogéneas, que resultan de una elección especial de los coeficientes, está dado por

\[
y(a)=y(b),\quad y'(a)=y'(b).
\]

Las ecuaciones se llaman \textbf{condiciones de contorno periódicas} y significa que las soluciones se pueden expresar en t'erminos de sus \emph{series de Fourier}. Nótese que las condiciones periódicas están acopladas, no separadas.
\begin{def.}[Wronskiano]
Para cualesquiera dos funciones \(f,g\in C^1\), el determinante
\[
W(f, g)(x) = \begin{vmatrix}
f(x) & g(x) \\
f'(x) & g'(x)
\end{vmatrix} = f(x)g'(x) - g(x)f'(x)
\]
se llama el \textbf{Wronskiano} de \( f \) y \( g \). El símbolo \( W(f, g)(x) \) a veces se abrevia como \( W(x) \).
\end{def.}

El Wronskiano deriva su importancia en el estudio de ecuaciones diferenciales de los siguientes lemas.

\begin{lema}
Si \(y_1\) y \(y_2\) son soluciones de la ecuación homogénea
\begin{equation}\label{eq-homogenea}
y''+p(x)y'+q(x)y=0,\quad x\in I,
\end{equation}
donde \(q in C(I)\), entonces o bien \(W(y_1,y_2)(x)=0\) para todo \(x\in I\), o bien \(W(y_1,y_2)(x)\neq0\) para cualquier \(x\in I\).
\end{lema}
\dem Recodamos que \(W(y_{1},y_{2})(x)=y_{1}(x)y'_{2}(x)-y'_{1}(x)y_{2}(x)\), entonces al clacular su derivada se obtiene que
\[
  W'(y_{1},y_{2})=(y'_{1}y'_{2}+y_{1}y^{''}_{2})-(y^{''}_{1}y_{2}+y'_{1}y'_{2})=y_{1}y^{''}_{2}-y^{''}_{1}y_{2}.
\]
Ahora como \(y_{1}\),\(y_{2}\) son soluciones de la ecuaci'on homogenea \ref{eq-homogenea}, entonces
\begin{align*}
  y_1''+p(x)y_1'+q(x)y_1=0\\
  y_2''+p(x)y_2'+q(x)y_2=0.\\
\end{align*}
Por lo que si multipllicamos por \(y_{2}\) a la primera ecuaci'on y por \(y_{1}\) a la primera, obtenemosl al restarlas
\begin{align*}
  & y''_{2}(x)y_1(x)-y(x)_{2}y''_1(x) + p(x)(y'_{2}y_1-y_{2}(x)y_1'(x))=0\\
  &\text{entonces } W'(y_{1},y_{2})(x) + p(x)W(y_{1},y_{2})(x)= 0.\\
\end{align*}
As'i al integrar se obtiene que
\[
  W(y_{1},y_{2})=c\exp\left(-\int_{a}^{x}p(t)\,dt\right)\quad x\in I.
\]
\QED\\
\obs Las consecuencias del lema anterior son que las soluciones de la ecuaci'on \ref{eq-homogenea} o son \emph{linealmente independientes} o son linealmente dependientes.
\section{Los ceros de las soluciones}
\noindent Resolver ecuaciones diferenciales es en general bastante complicado e incluso imposible, por lo menos explicitamente en t'erminos de funciones elementales. Sin embargo es posible obterer informaci'on qualitativa de las soluciones, por ejemplo es posible determinar ortogonalidad de las soluciones. Este es un tema amplio en el estudio de las ecuaciones diferenciales, sin embargo en esta secci'on estudiaremos los ceros de la ecuaciones lineales de orden dos, ya que incluso estas no siempre tienen soluciones en t'erminos de funciones elementales. En concreto primero estudiaremos los ceros de las soluciones a ecuaciones del tipo

\begin{equation}
y''+p(x)y'+q(x)y=0,\quad x\in I,
\end{equation}

Primero, estudiamos el ejemplo protot'ipico de estas ecuaciones (uno que s'i es \emph{soluble}) y luego veremos que el comportamieto de sus ceros son t'ipicos para este tipo de ecuaciones.

\eje La ecuaci'on de segundo grado m'as simple
\[
  y''(x)+y(x)=0\quad x\in\re.
\]
Cuyas soluciones linealmente independientes son \(\cos(x)\) y \(\sin(x)\) (las bases de los fen'omenos ondulatorios), ya que como podemos observar
\[
  W(\cos,\sin)(x)=\cos^{2}(x)+\sin^{2}(x)=1,
\]
es decir en general las soluciones son de la forma
\[
  y(x)=c_{1}\cos(x)+c_{2}\sin(x).
\]
Ahora si nos fijamos \(\sin(x)=0\) si \(x\in\{n\pi\,:\,n\in\zah\}\) y \(\cos(x)=0\) si y s'olo si \hbox{\(x\in\{(2k+1)/2\pi\,:\,k\in\zah\}\)}. Es decir, por la forma ondulatoria de las soluciones, los ceros son \emph{aisaldos e intercalados}
\[
  \dots-\frac{3\pi}{2}<-\pi<-\frac{\pi}{2}<0<\frac{\pi}{2}<\pi<\frac{3\pi}{2}<\dots
\]
Ahora, si modificamos esta ecuaci'on un poco a la ecuaci'on
\[
  y''(x)+ky(x)=0\quad k\in\re\text{ constante y }x\in\re,
\]
si \(k>0\) las soluciones son practicamente las mismas y s'olo se multiplica por \(k\) en el argumento y los ceros siguen siendo aislados e intercalados, sin embargo si \(k<0\), entonces las soluciones son \(e^{\sqrt{|k|}x}\) y \(e^{-\sqrt{|k|}x}\) la cuales nunca se anulan y las combiaciones lineales tienen a lo m'as un cero.

\begin{lema}
  Si \(y(x)\) es una soluci'on no trivial de la ecuaci'on \ref{eq-homogenea}, entonces los ceros de \(y(x)\) son aislados en \(I\).
\end{lema}
\dem Si \(y(x_{0})=0\), entonces \(y'(x_{0})\neq0\) pues por unicidad, si la derivada se anula, \(y\) ser'ia la soluci'on trivial, por lo que \(y'(x)\neq\) en un subinvervalo de \(I\) \((\epsilon-x_{0},\epsilon-x_{0})\), lo cual implica que alredor de \(x_{0}\), \(y\) es \textbf{extrictamente} creciente o decreciente y por lo que no hay ning'un otro cero en dicho intervalo.
\QED\\

\begin{teorema}[Teorema de separaci'on de Sturm]
Si \(y_1\) y \(y_2\) son soluciones linealmente independientes de la ecuación
\[
y''+p(x)y'+q(x)y=0, \quad x\in I,
\]
entonces los ceros de \(y_1\) son distintos de los de \(y_2 \), y las dos secuencias de ceros se alternan, es decir, \(y_1\) tiene exactamente un cero entre dos ceros sucesivos de \(y_2\), y viceversa.
\end{teorema}
\dem Dado que \(y_1\) y \(y_2\) son linealmente independientes, su Wronskiano
\[
W(y_1,y_2)(x)=y_1(x)y_2'(x)-y_2(x)y_1'(x)
\]
no se anula y, por lo tanto, tiene un signo constante en \(I\). Nótese primero que \(y_1\) y \(y_2\) no pueden tener un cero común, de lo contrario \(W\) se anularía ahí. Entonces, suponemos que \(x_1\) y \(x_2\) son dos ceros sucesivos de \(y_2\) respectivamente, entonces
\begin{align*}
W(x_1)&=y_1(x_1)y_2'(x_1)\neq0,\\
W(x_2)&=-y_1(x_2) y_2'(x_2)\neq0,
\end{align*}
y los números \(y_1(x_1)\), \(y_1(x_2)\), \(y_2'(x_1)\) y \(y_2'(x_2)\) son todos distintos de cero. Dado que \(y_2'\) es continua en \(I\), \(x_1\) tiene una vecindad abierta \(U_1\) donde el signo de \(y_2'\) no cambia, y de manera similar existe un abierto \(U_2\) de \(x_2\) donde \(y_2'\) no cambia de signo. Sin embargo, los signos de \(y_2'\) en \(U_1\cap I\) y \(U_2\cap I\) no pueden ser iguales, ya que si \(y_2\) es creciente en uno de los intervalos, entonces debe ser decreciente en el otro. Para que \(W(x)\) tenga un signo constante en \(I\), \(y_1(x_1)\) y \(y_1(x_2)\) deben tener signos opuestos; por lo tanto, \(y_1\), siendo continua, tiene al menos un cero entre \(x_1\) y \(x_2\). No puede haber más de un cero, ya que si \(x_3\) y \(x_4\) son dos ceros de \(y_1\) que se encuentran entre \(x_1\) y \(x_2\), podemos usar el mismo argumento para concluir que \(y_2\) se anula entre \(x_3\) y \(x_4\). Pero esto contradice la suposición de que \(x_1\) y \(x_2\) son ceros consecutivos de \(y_2\).\QED\\
\begin{cor}
Si dos soluciones de \(y''+p(x)y'+q(x)y=0\) tienen un cero común en \(I\), entonces son linealmente dependientes.
\end{cor}
Para estudiar la distribución de ceros de la ecuación \ref{eq-homogenea}, sería mucho más conveniente si pudiéramos eliminar el término medio \(qy'\) transformando la ecuación a
\[
u''+\rho(x)u=0.
\]
Para ello lo que se hace es tomar
\[
y(x)=u(x)v(x),
\]
de modo que
\begin{align*}
y'(x) &= u'(x) v(x) + u(x) v'(x),\\
y''(x) &= u''(x) v(x) + 2 u'(x) v'(x) + u(x) v''(x).
\end{align*}
Sustituyendo en la ecuación obtenemos
\[
v(x)u''(x)+ (2v'(x)+p(x)v(x))u'(x) + (v''(x)+p(x)v'(x)+r(x)v(x))u(x)=0.
\]
Así, eligiendo \(2v'(x)+p(x)v(x)=0\), tenemos que
\[
v(x)=\exp\left(-\frac{1}{2}\int_a^xp(t)\,dt\right),
\]
y
\[
\rho(x)=q(x)-\frac{1}{4}p^2(x)-\frac{1}{2}p'(x).
\]
La función exponencial \(v\) nunca se anula en \(\re\), por lo que los ceros de \(u\) coinciden con los de \(y\).
\begin{teorema}[Teorema de Comparación de Sturm]\label{strum-comp}
Sean \(\phi\) y \(\psi\) soluciones no triviales de las ecuaciones
\[
y''+r_1(x)y=0,\quad u''(x)+r_2(x)u(x)=0,\quad x\in I,
\]
respectivamente, y supongamos que \(r_1(x)\geq r_2(x)\) para todo \(x\in I\). Entonces, \(\phi\) tiene al menos un cero entre cada dos ceros consecutivos de \(\psi\), a menos que \(r_1(x)\equiv r_2(x)\) y \(\phi\) sea un múltiplo constante de \(\psi\).
\end{teorema}
\dem Sean \(x_1\) y \(x_2\) dos ceros consecutivos de \(\psi\) en \(I\), y supongamos que \(\phi\) no tiene ceros en el intervalo abierto \((x_1,x_2)\). Asumamos que tanto \(\phi\) como \(\psi\) son positivas en \((x_1, x_2)\); de lo contrario, cambiamos el signo de la función negativa. Dado que \(\phi'\) y \(\psi'\) son continuas, se sigue que \(\psi'(x_1)\geq0\) y \(\psi'(x_2)\leq0\), y por lo tanto, el Wronskiano de \(\phi\) y \(\psi\) satisface
\[
W(x_1)=\phi(x_1)\psi'(x_1)\geq0,\quad W(x_2)=\phi(x_2)\psi'(x_2)\leq 0.
\]
Pero como
\[
W'(x)=\phi(x)\psi''(x)-\phi''(x)\psi(x)=[r_1(x)-r_2(x)]\phi(x)\psi(x)\geq0\quad\forall x\in(x_1,x_2),
\]
\(W\) es una función creciente en \((x_1,x_2)\). Esto contradice las desigualdades anteriores a menos que \(r_1(x)-r_2(x)\equiv0\) y \(W(x)\equiv0\), en cuyo caso \(\phi\) y \(\psi\) son linealmente dependientes.
\QED\\
\begin{cor}
Sea \(\phi\) una solución no trivial de \(y''+r(x)y=0\) en \(I\). Si \(r(x)\leq0\), entonces \(\phi\) tiene a lo sumo un cero en \(I\).
\end{cor}
\dem Si la solución \(\phi\) tiene dos ceros en \(I\), digamos \(x_1\) y \(x_2\), entonces, por el Teorema \ref{strum-comp}, la solución \(\psi(x)\equiv1\) de \(u''= 0\) debe anularse en \((x_1,x_2)\), lo cual es imposible.
\begin{def.}
  Si una soluci'on de \ref{eq-homogenea}, tiene infinitos ceros, entonces diremos que las soluciones son \emph{ondulatorias}.
\end{def.}
\eje Veremos que la funciones de Bessel son \emph{ondulatorias}. Las funciones de Bessel son las soluciones a las ecuaciones
\begin{equation}\label{eq-bessel}
  y''+\frac{1}{x}y'+\left(1-\frac{\nu^{2}}{x^{2}}\right)y=0,\quad x\in\re^{+}
\end{equation}
conocidas como las \emph{ecuaciones de Bessel de orden\(\nu\).} Multiplicando por \(v(x)=e^{1/2\log(x)}=\sqrt{x}\), estas ecuaciones se transforman en
\[
  u''+\left(1+\frac{1-4\nu^{2}}{4x^{2}}\right)u=0.
\]
Observamos que
\[
  q(x)=1+\frac{1-4\nu^{2}}{4x^{2}}\implies\begin{cases}
                                          q(x)\geq1\text{ si } \nu\in[0,\frac{1}{2}],\\
                                          q(x)<1\text{ si } \nu>\frac{1}{2}.\\
                                         \end{cases}
\]
Ahora podemos comparar con \(u''+u=0\) para obtener que para cualquier soluci'on a la ecuaci'on de Bessel se cumple alguna de las siguientes opciones
\begin{enumerate}
\item[i)] Si \(\nu\in[0,1/2]\), entonces todos los subintervalos de \(\re^{+}\) de longitud \(\pi\) tienen \textbf{por lo menos} un cero.
\item[ii)] Si \(\nu>1/2\), entonces todos los intervalos de longitud \(pi\) de \(\re^{+}\) tienen \textbf{al menos} un cero.
\item[iii)]Si\(\nu=1/2\), entonces la distancia entre ceros es \textbf{exactemente} \(pi\).

\end{enumerate}
\section{Operadores adjuntos de Hilbert}
\noindent Ahora pensaremos a las ecuaciones previamente mencionadas como \emph{operadores} en \(\mathcal{L}^{2}(I)\), entonces hablaremos un poco de \emph{operadores lineales en espacios de Hilbert} de la forma $T:V\subset\mathcal{H}\to\mathcal{H}$. Recordemos que el dominio e imagen se definen como
\begin{itemize}
    \item El \textbf{dominio} de $T$, denotado $\mathcal{D}(T)$, es el subespacio de $\mathcal{H}$ donde $T$ está definido.
    \item La \textbf{imagen} de $T$, denotado $\mathcal{R}(T)$, es el conjunto $Im(T)=\{T(x) : x \in \mathcal{D}(T)\}$.
\end{itemize}
En los epacios de Hilbert es posible definir a partir de un operador lineal y continuo, \(T\) un operador especial \(T^{*}\), el cual es llamado el \emph{operador adjunto de Hilbert de \(T\)}. Vale la pena mencionar que la noci'on de \emph{operador adjunto} es genral y no necesariamente exclusiva a los espacios de Hilbert o espacios con producto interno, sin embargo la retpresentaci'on que usaremos utilizando el producto interno, s'i es unica en esoacios de Hilbert. Podemos definir y representar al operador adjunto gracias al \textbf{teorema de representaci'on de Riez} (teorema \ref{riez}), ya que para \(T\) lineal, entonces para todo \(\bra{\psi}\in\mathcal{H}^{*},\,\ket{\phi}\mapsto\braket{\psi|T(\phi)}\) tambi'en es lineal, entonces por representaci'on de Riez exite un \emph{bra que depende de} \(\psi\), al cual denotamos por \(T^{*}\bra{\psi}\in\mathcal{H}^{*}\) tal que
\[
  \braket{T^{*}(\psi)|\phi}=\braket{\psi| T(\phi)}, \quad \forall \ket{\phi} \in \mathcal{D}(T), \, \bra{\psi} \in \mathcal{D}(T^*).
\]
\noindent Adem'as como \(\braket{\cdot|\cdot}\) y \(T\) son lineales, entonces \(T^{*}:D(T^{*})\to\mathcal{H}^{*}\) es un operador lineal y si \(T\) es \emph{acotado}, entonces \(T^{*}\) tambi'en lo es.

\begin{def.}
Dado un operador $T$ en $\mathcal{H}$, su \textbf{adjunto} $T^*$ es el operador que satisface
\[
\braket{T^{*}(\psi)|\phi}=\braket{\psi| T(\phi)}, \quad \forall \ket{\phi} \in \mathcal{D}(T), \, \bra{\psi} \in \mathcal{D}(T^*).
\]
\end{def.}
\obs Si $\braket{\phi|\psi}=0$ para toda $\psi$, entonces $\bra{\phi}=0$ pues $\|\phi\|^{2}=\braket{\phi|\phi}=0$, por esto mismo si $\braket{\phi|T\psi}=0$ para toda $\bra{\phi}$, entonces $T=0$, o equivalentemente
\[
  \braket{\phi|T\psi}=\braket{\phi|S\psi},\,\forall\ket{\phi},\ket{\psi}\in\mathcal{H}\implies\,S=T.
\]
\noindent\textbf{Propiedades del Adjunto}
\begin{enumerate}
  \item $(T + S)^* = T^* + S^*$ si $\mathcal{D}(T) \cap \mathcal{D}(S)$ es denso.
  \item $(TS)^* = S^* T^*$ si $\mathcal{D}(TS)$ es denso.
  \item $(T^*)^* = T$ (si $T$ es cerrado y densamente definido).
  \item $(\alpha T)^* = \overline{\alpha} T^*$ para $\alpha \in \co$.
  \item $\|T\|=\|T^{*}\|$, o equivalentemente $\|T\|^{2}=\|T^{*}\|\|T\|=\|T\|\|T^{*}\|$.
  \item Si $\lambda$ es valor propio de $T$, entonces $\overline{\lambda}$ es valor propio de $T^{*}$.
\end{enumerate}
\dem Sean $\ket{\phi}$ y $\ket{\psi}$ arbitarios, para demostrar $1.$, simplemente calculamos
\begin{align*}
  \braket{(S+T)^{*}\phi|\psi}&=\braket{\phi|(S+T)\psi}=\braket{\phi|S\psi+T\psi}\\
  &=\braket{\phi|T\psi}+\braket{\phi|S\psi}=\braket{T^{*}\phi|\psi}+\braket{S^{*}\phi|\psi}=\braket{(S^{*}+T^{*})\phi|\psi}.
\end{align*}
Por lo tanto $(S+T)^{*}=S^{*}+T^{*}$, para $2.$
\[
  \braket{\phi|TS\psi}=\braket{T^{*}\phi|S\psi}=\braket{S^{*}T^{*}\phi|\psi}.
\]
$3.$ Sea $(T^{*})^{*}=T^{**}$, entonces comprobamos que para todo $\ket{\phi},\ket{\psi}\in\mathcal{D}(T)$, se cumple
\[
  \braket{T^{**}\phi|\psi}=\braket{\phi|T^{*}\psi}=\braket{T\phi|\psi}.
  \]
Por lo tanto $T=T^{**}$, si $T$ es cerrado y densamente definida, es decir $\mathcal{D}(T)=\mathcal{H}$. Para $4.$,
\[
  \braket{\phi|(\alpha T)\psi}=\braket{\phi|\alpha(T\psi)}=\braket{\overline{\alpha}\phi|T\psi}=\braket{T^{*}(\overline{\alpha}\phi)|\psi}=\braket{\overline{\alpha}T^{*}\phi|\psi}.
\]
Por lo tanto $(\alpha T)^{\alpha}=\overline{\alpha}T^{*}$. Para $5.$, por los incisos $2.$ y $3.$, $(T^{*}T)^{*}=T^{*}T$ simplemente calculamos para toda $\ket{\phi}$
\[
  \|T\phi\|^{2}=\braket{T\phi|T\phi}=\braket{T^{*}T\phi|\phi}\leq\|T^{*}\|T\|\|\phi\|^{2}.
\]
Lo que implica que $\|T\|^{2}\leq\|T^{*}\|\|T\|$, haciendo lo mismo con $T^{*}$ y recordando que $T^{**}=T$ se obtiene la otra desigualdad, notamos que esto implica que $T^{*}T=0$, entonces $T=0$ pues $\|T\|$ es norma.
Por 'ultimo, sea $\lambda$ valor propio de $T$ y $\ket{\phi}$ es tal que $T\phi=\lambda\ket{\phi}$, entonces sea $\ket{\psi}$
\[
  \braket{\overline{\lambda}\psi|\phi}=\braket{\psi|\lambda\phi}=\braket{\phi|T\phi}=\braket{T^{*}\psi|\phi}
\]
Como $\ket{\psi}$ es arbitraria, entonces tiene que existir una tal que $T^{*}\psi=\overline{\lambda}\ket{\psi}$.
\begin{def.}{Operadores Autoadjuntos}
Un operador $T$ es \textbf{autoadjunto} si $T = T^*$, es decir
\[
  \braket{T(\psi)|\phi}=\braket{\psi| T(\phi)}, \quad \forall \ket{\phi} \in \mathcal{D}(T), \, \bra{\psi} \in \mathcal{D}(T^*).
\]
Los operadores autoadjuntos son fundamentales en mecánica cuántica, ya que representan observables físicos.
\end{def.}
\eje Para todo operador $T$, como vimos anteriormente $S=T^{*}T$ es autoadjunto pues
\[
  S^{*}=(T^{*}T)^{*}=T^{*}T^{**}=T^{*}T=S.
\]
\eje\textbf{Matrices Hermitianas}
En $\mathcal{H} = \con$, un operador $T$ puede representarse como una matriz $A\in\co^{n \times n}$. $A$ es \textbf{Hermitiana} (autoadjunta) si:
\[
A = A^*, \quad \text{donde } A^* = \overline{A}^T.
\]
Por ejemplo, la matriz
\[
A = \begin{pmatrix}
2 & i \\
-i & 3
\end{pmatrix}
\]
es Hermitiana, ya que $A^* = A$.

Algunas propiedades de los operadores autoadjuntos
\begin{itemize}
  \item Sus valores poropios son reales ya que si \(\ket{\phi}\) es vector propio de norma uno de $T$ autoadjunto con valor propio \(\lambda\), entonces
        \begin{align*}
        \lambda=\lambda\|\phi\|^{2}=\lambda\braket{\phi|\phi}=\braket{\phi|\lambda\phi}=\braket{\phi|T\phi}=\braket{T\phi|\phi}=\overline{\lambda}
        \end{align*}
  \item Sus vectores propios de valores distintos son ortogonales, es decir, si $\ket{\phi}$ tiene valor propio $\lambda$ y $\ket{\psi}$ tiene valor propio \emph{distinto} $\mu$, entonces
        \begin{align*}
        \lambda\braket{\psi|\phi}=\braket{\psi|\lambda\phi}=\braket{\psi|T\phi}=\braket{T\psi|\phi}=\braket{\mu\psi|\phi}=\mu\braket{\psi|\phi}
        \end{align*}
        Recordamos que $\mu$ es real por el punto anterior, entoces si $\braket{\psi|\psi}$ no es cero $\mu=\lambda$ lo cual es imposible.
\end{itemize}
\eje\textbf{Operadores Unitarios}
Un operador $U$ es \textbf{unitario} si
\[
U^* U = U U^* = I,
\]
donde $I$ es el operador identidad. Los operadores unitarios preservan el producto interno
\[
\braket{ U(x)| U(y)} = \braket{ x | y}, \quad \forall x, y \in \mathcal{H}.
\]

\eje\textbf{Matrices Unitarias}
En $\mathbb{C}^n$, una matriz $U \in \mathbb{C}^{n \times n}$ es unitaria si
\[
U^* U = U U^* = I.
\]
Por ejemplo, la matriz
\[
U = \frac{1}{\sqrt{2}} \begin{pmatrix}
1 & -i \\
1 & i
\end{pmatrix}
\]
es unitaria, ya que $U^* U = I$.
\begin{teorema}[Teorema Espectral]
Sea \(T\) un operador autoadjunto (matriz hermitiana) en $\con$, entonces existe una base ortonormal de \(\con\) de vectores propios tal que la matriz de cambio de base \(U\) es unitaria y
\[
UTU^{*}= \begin{pmatrix}\lambda_{1}& 0 & \dots & 0\\ 0 & \lambda_{2} & \dots & 0\\ \vdots & \vdots & \cdots & \vdots\\ 0 & 0 & \dots & \lambda_{n} \end{pmatrix}
\]
\end{teorema}
\obs Notamos que si $T$ es autoadjunto l'imite de operadores con rango de dimensi'on finita, entonces es v'alido  el teorema espectral para $T$ si lo hacemos en cada uno de sus componentes de dimension finita.
\subsection{Operadores de Sturm-Liouville autoadjuntos}
\noindent Ahora veremos cu'al es el adjunto de un operador diferencial ordinario de orden dos
\[
L=a_0(x)\frac{d^2}{dx^2}+a_1(x)\frac{d}{dx}+a_2(x)I,\quad x\in [a,b]\subset\re,\{a_{0},a_{1},a_{2}\}\subset\mathcal{C}^{2}[a,b]
\]
El cual se define como un operador
\[
  L:\mathcal{L}^{2}([a,b],\mu)\cap\mathcal{C}^{2}[a,b]\to\mathcal{L}^{2}([a,b],\mu).
\]
\noindent Donde $\mu$ va a ser la \emph{medida de Lebesgue} $\lambda$ o una medida derivada de la misma. Ahora usamos integraci'on por partes para calcular $L^{*}$
\begin{align*}
  \braket{\phi|L\psi}&=\int_{a}^{b}\overline{\phi}(a_{0}(x)\psi''+a_{1}(x)\psi'+a_{2}(x)\psi)\,d\lambda(x)\\
                     &=\int_{a}^{b}a_{0}\overline{\phi}\psi''+a_{1}\overline{\phi}\psi'+a_{2}\overline{\phi}\psi\,d\lambda(x)\\
                     &=a_{0}\overline{\phi}\psi'|_{a}^{b}-\int_{a}^{b}(a_{0}(x)\overline{\phi})'\psi'\,d\lambda(x)\\
                     &+a_{1}\overline{\phi}\psi|_{a}^{b}-\int_{a}^{b}(a_{1}(x)\overline{\phi})'\psi\,d\lambda(x)
                     +\int_{a}^{b}\overline{\phi}a_{2}\psi\,d\lambda(x)\\
                     &=(a_{0}\overline{\phi}\psi'-\psi(a_{0}\overline{\phi})')|_{a}^{b} +\int_{a}^{b}(a_{0}(x)\overline{\phi})''\psi\,d\lambda(x)\\
                     &a_{1}\overline{\phi}\psi|_{a}^{b}-\int_{a}^{b}(a_{1}\overline{\phi})'\psi\,d\lambda
                       +\int_{a}^{b}\overline{\phi}a_{2}\psi\,d\lambda(x)\\
                     &=\braket{(\overline{a_{0}}\phi)''-(\overline{a_{1}}\phi)'+\overline{a_{0}}\phi|\psi}+
                       [a_{0}(\overline{\phi}\psi'-\psi\overline{\phi}')+(a_{1}-a_{0}')\overline{\phi}\psi]|_{a}^{b}
\end{align*}
Esto es indicativo de la definici'on de $L^{*}$, es decir definimos $L^{*}$ el \emph{adjunto formal} como
\begin{align*}
  L^{*}\phi(x)&=(\overline{a_{0}}(x)\phi)''-(\overline{a}_{1}(x)\phi)'+\overline{a_{2}}(x)\phi\\
             &=\overline{a_{0}(x)}\phi''+(2\overline{a_{0}(x)}'-\overline{a_{1}(x)})\phi'+(\overline{a_{0}(x)}''-\overline{a_{1}(x)}'+\overline{a_{2}(x)}\phi
\end{align*}
Por lo tanto,
\[
  L^{*}=\overline{a_0(x)}\frac{d^2}{dx^2}+(2\overline{a_{0}(x)}'-\overline{a_1(x)})\frac{d}{dx}+(\overline{a_{0}(x)}''-\overline{a_{1}(x)}'+\overline{a_2(x)})I.
\]
Entonces para que $L$ sea \emph{formalmente autoadjunto,} es necesario que
\[
  \overline{a_{0}}=a_{0},\quad 2\overline{a_{0}}'-\overline{a_{1}}=a_{1},\quad\overline{a_{0}}''-\overline{a_{1}}'+\overline{a_{2}}=a_{2},
\]
es decir, $a_{0}$, $a_{1}$ y $a_{2}$ son funciones \emph{reales} y $a_{1}=a_{0}'$, en cuyo caso, escribimos $a_{0}=p$ y $a_{2}=q$ y por lo tanto el operador se escribe de la forma
\[
    L=\frac{d}{dx} \left( p(x) \dfrac{d}{dx} \right) + q(x)I,
\]
los cuales ya hab'iamos definido como \emph{operadores de Sturm-Liouville}. Ahora para que $L$ sea \emph{auto adjunto}, es necesario que se cumpla
\[
  p(x)(\phi(x)'\overline{\psi(x)}-\phi(x)\overline{\psi(x)'})=0\text{ para todas }x\in(a,b)\,\text{ y }\phi,\psi.
\]
Ahora, nosotros estaremos interesados en el problema de valores propios de $-L$, es decir en resolver ecuaciones del tipo
\[
  Lu+\lambda u=0.
\]
La raz'on por la cual nos interesan los valores propios de $L$ y no de $-L$ es porque los valores propios de $L$ resultan negativos cuando $p>0$, como el caso de $y''+ky=0$.

\eje El operador $L=-(\dfrac{d^{2}}{dx^{2}})$ es formalmente autoadjunto ($p=-1$ y $q=0$), recordamos que sus \emph{eigenfunciones o funciones propias} son las soluciones a la ecuaci'on
\[
  u''+\lambda u=0.
\]
M'as a'un si imponemos condiciones de forntera $u(0)=u(\pi)=0$ entonces es f'acil ver que necesariamente $\lambda>0$ y como se vio previamente los vectores propios normalizados son los monomios trigonom'etricos
\[
  \sqrt{\frac{2}{\pi}}\sin(nx)\quad n\in\nat.
\]
Los cuales sabemos que son \emph{ortonormales}.

\noindent Ahora, \textbf{¿Qu'e se puede hacer cuando $a_{0}'\neq a_{1}$ en $L$?}. Resulta que podemos multiplicar a $L$ por una funci'on positiva $\rho(x)>0$ de tal forma que $L$ es \emph{formalmente autoadjunto} para un \emph{producto punto} modificado o \emph{medida modificada}. Primero, sea
\[
L=a_0(x)\frac{d^2}{dx^2}+a_1(x)\frac{d}{dx}+a_2(x)I,\quad x\in [a,b]\subset\re,
\]
\noindent donde $a_{0}\in\mathcal{C}^{2}(a,b)$ $a_{1}\in\mathcal{C}^{1}(a,b)$ y $a_{2}\in\mathcal{C}[a,b]$, entonces si consideramos el operador $\tilde{L}=\rho L$, sabemos por lo anteriormente discutido que $\tilde{L}$ es formalmente autoadjunto si y s'olo si
\[
  \rho a_{1}=(\rho a_{0})'=\rho'a_{0}+\rho a_{0}',
\]
esta es una ecuaci'on diferencial de orden uno cuya soluci'on claramente es
\[
  \rho(x)=\frac{c}{a_{0}(x)}\exp\left(\int_{a}^{x}\frac{a_{1}(t)}{a_{0}(t)}\,dt\right).
\]
Escogiento una $c$ adecuada podemos suponer que $\rho(x)>0$. Por lo tanto simempre podemos multiplicar a $L$ por una funcion positiva tal que el resultado sea formalmene autoadjunto sin embargo
\begin{equation} \braket{\phi|\psi}_{\rho}=\int_{a}^{b}\overline{\phi(x)}\psi(x)\rho(x)\,d\lambda(x)=\int_{a}^{b}\overline{\phi(x)}\psi(x)\,d\mu_{\rho}(x).
\end{equation}
\end{document}
