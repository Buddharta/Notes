\documentclass[main.tex]{subfiles}
\begin{document}
\chapter{Aplicaciones a las Ecuaciones Diferenciales Parciales}
\noindent En este cap'itulo aplicaremos las t'ecnicas y teorias de los cap'itulos anteriores en las ecuaciones deferenciales parciales lineales. Para hacer esto, haremos uso de diversas t'ecnicas que permiten ``disminuir'' la dimensionalidad del problema, para as'i obtener una ecuaci'on diferencial ordinaria, estas t'ecnicas incluyen el m'etdo de Bernoulli y el uso de coordenadas adecuadas, sin embargo estas tecnicas se pueden asociar a m'etodos de \emph{simetr'ias y acciones de grupos de Lie} adem'as de sus \emph{funciones especiales} asociadas, sin embargo no hermos uso de esta tecnicas ya que salen del enfoque del curso.

M'as a'un nos enfocaremos en las ecuaciones parciales m'as comunes, en espec'ifico: \emph{la ecuaci'on de Laplace, la ecuaci'on de calor y la ecuaci'on de onda,} las cuales corresponden con los tipos de operadores: \emph{el'ipticos, parabo'olicos e hiperb'olicos} respectivamente, discutiremos un poco sobre estos, mostraremos el origen de esta clasificacion en el caso de ecuaciones parciales lineales en dos variables, pero los ejemplos protot'ipicoa tambi'ern ser'an discutidos en m'as variables.

\section{Metodo de Bernoulli}
\noindent Aunque es un m'etodo que ya utilizamos en \ref{cap2-schro} y la asumimos en el inicio de \ref{cap3}. Sin embargo ahora lo veremos con mayor profundidad, cabe mencionar que en lugar de resolver una ecuaci'on parcial con condiciones de frontera usando ecuaciones ordinarias, lo que se busca con el \emph{m'etodo de Bernoulli}, es encontrar infinitas soluciones a una ecuaci'on parcial donde \textit{casi} se cumplan las condiciones de frontera y buscar la soluci'on esparada como una \emph{combinacion} de 'estas, es por eso que tambi'es es necesario mecnionar el \emph{principio de superposici'on} en esta secci'on. Cabe mencionar que a pesar de que se ha utilizado para las ecuaciones parciales que hemos encontrado, no siempre se puede aplicar, a continuaci'on vemos qu'e condiciones se tienen que cumplir
\begin{teorema}
  Consideremos la siguiente ecuacion definida por un \emph{operador diferencial lineal parcial de orden dos} en dos variables general;
  \begin{equation}\label{edp-lin-ord-2}
    a_{11}\dfrac{\partial^{2}\phi}{\partial\xi^{2}}+2a_{12}\dfrac{\partial^{2}\phi}{\partial\xi\partial\eta}+
    a_{22}\dfrac{\partial^{2}\phi}{\partial\eta^{2}}+a_{10}\dfrac{\partial\phi}{\partial\xi}+
    a_{01}\dfrac{\partial\phi}{\partial\eta}+a_{00}\phi=0.
  \end{equation}
  M'as a'un supongamos existe un cambio de coordenadas
\begin{equation}
  \begin{cases}
    x=x(\xi,\eta)\\
    y=y(\xi,\eta),
  \end{cases}
    \quad\text{donde}\quad
    \begin{vmatrix}
      \partial_{\xi}x && \partial_{\eta}x\\
      \partial_{\xi}y && \partial_{\eta}y
    \end{vmatrix}\neq0,\\
  \end{equation}
  tal que la ecuaci'on resultante quede del tipo
  \begin{equation}\label{edp-lin-red-2}
    \alpha_{11}\dfrac{\partial^{2}\phi}{\partial x^{2}}+\alpha_{22}\dfrac{\partial^{2}\phi}{\partial y^{2}}
    +\alpha_{10}\dfrac{\partial\phi}{\partial x}+\alpha_{01}\dfrac{\partial\phi}{\partial y}+\alpha_{00}\phi=0.
  \end{equation}
  Es decir que no contiene un t'ermino con derivadas \emph{cruzadas} y por 'ultimo, si exite una funci'on $\beta(x,y)$ tal que los cocientes cumplen:
  \begin{align*}
    \frac{\alpha_{11}}{\beta}&=\gamma_{11}(x),\frac{\alpha_{10}}{\beta}=\gamma_{10}(x),\text{ dependen s'olo de }x.\\
    \frac{\alpha_{22}}{\beta}&=\gamma_{22}(y),\frac{\alpha_{01}}{\beta}=\gamma_{01}(y),\text{ depende s'olo de }y.\\
    \frac{\alpha_{00}}{\beta}&=\Gamma_{1}(x)+\Gamma_{2}(y).
  \end{align*}
  Entonces el m'etodo de Bernoulli reduce la ecuaci'on \ref{edp-lin-ord-2} a dos ecuaciones diferenciales ordinarias lineales.
  \end{teorema}
  \dem Supongamos que la ecuaci'on se encuentra en forma reducida \ref{edp-lin-red-2} y sustituimos
  \[
    \phi(x,y)=\varphi(x)\psi(y).
  \]
  As'i obtenemos
  \begin{align*}
    &\alpha_{11}(x,y)\varphi(x)''\psi(y)+\alpha_{22}(x,y)\varphi(x)\psi''(y)+\alpha_{10}(x,y)\varphi(x)'\psi(x)+\\
    &\alpha_{01}(x,y)\varphi(x)\psi'(y)+\alpha_{00}(x,y)\varphi(x)\psi(y)=0.
  \end{align*}
  Ahora por las hi'otesis podemos dividir entre la funci'on
  \[
    \beta(x,y)\varphi(x)\psi(y),
  \]
  para obteber la siguiente ecuaci'on, donde separamos los t'erminos dependientes de ``x'' y los dependientes de ``y'' para obterner
  \begin{equation}
    \gamma_{11}(x)\frac{\varphi''(x)}{\varphi(x)}+\gamma_{10}(x)\frac{\varphi'(x)}{\varphi(x)}+\Gamma_{1}(x)=
    -\left(\gamma_{22}(y)\frac{\psi''(y)}{\psi(y)}+\gamma_{01}(y)\frac{\psi'(y)}{\psi(y)}+\Gamma_{2}(y)\right)
  \end{equation}
  Asi similarmente a lo que hicimos en \ref{cap2-schro}, como ambas son ecuaciones dependientes de distintas variables, es decir, ambas ecuaciones son iguales a una constante $\lambda$ y obtenemos
  \begin{align*}
    &\gamma_{11}(x)\varphi''(x)+\gamma_{10}(x)\varphi'(x)+\Gamma_{1}(x)\varphi(x)-\lambda=0\\
    &\gamma_{22}(y)\psi''(y)+\gamma_{01}(y)\psi'(y)+\Gamma_{2}(y)\psi(y)+\lambda\psi=0.
  \end{align*}
  \QED

  \obs El m'etodo de Bernoulli es aplicable para las ecuaciones de Schrodinger con potenciales independientes del tiempo.

  \eje Sea
  \[
      \dfrac{\partial^{2}\phi}{\partial r^{2}}+\frac{1}{r}\dfrac{\partial\phi}{\partial r}+\frac{1}{r^{2}}+\dfrac{\partial^{2}\phi}{\partial\theta^{2}}=0.
    \]
    En esta ecuacion tenemos $\alpha_{11}=1,\alpha_{10}=1/r,\alpha_{22}=1/r^{2}$. Adem'as no hay terminos de derivadas mixtas. En este caso $\beta=1/r^{2}$ y por lo tanto $\gamma_{22}=1,\gamma_{10}=r,\gamma_{11}=r^{2}$.

    \obs Se puede denmostrar que la ecuaci'on \ref{edp-lin-ord-2} siempre se puede reducir a una ecuacion de la forma
    \begin{enumerate}
      \item Si $a^{2}_{12}-a_{11}a_{22}>0$ la ecuaci'on se le llama \emph{hiperb'olica} y se reduce a
            \[
            \dfrac{\partial^{2}\phi}{\partial x^{2}}-\dfrac{\partial^{2}\phi}{\partial y^{2}}+\text{ derivadas de orden 1 y 0 }=0.
            \]
      \item Si $a^{2}_{12}-a_{11}a_{22}=0$ la ecuaci'on se le llama \emph{parab'olica} y se reduce a
            \[
            \dfrac{\partial^{2}\phi}{\partial x^{2}}+\text{ derivadas de orden 1 y 0 }=0.
            \]
      \item Si $a^{2}_{12}-a_{11}a_{22}<0$ la ecuaci'on se le llama \emph{el'iptica} y se reduce a
            \[
            \dfrac{\partial^{2}\phi}{\partial x^{2}}+\dfrac{\partial^{2}\phi}{\partial y^{2}}+\text{ derivadas de orden 1 y 0 }=0.
            \]
    \end{enumerate}

    \obs En m'as dimensiones el m'etodo de Bernoulli reduce la ecuacion parcial a un sistema igual al n'umero de dimensiones, pero se necesitan ajustar las hipotesis para incluir \emph{todas} las combinaciones de derivadas, algo que es complicado de escribir y por eso se omite. Adem'as la clasificaci'on tambi'en se usa para mayores dimensiones.
\section{Principio de Superposici'on}
\noindent Utilizando el m'etodo de Bernoulli, es posible reducir una ecuacion diferencial parcial lineal de orden $k$ en $n$ variables a un \emph{sistema de ecuaciones diferenciales ordinarias lineales de orden $k$}, en el caso anterior $k=2$ y $n=2$, por lo tanto se obtienen un sistema de dos ecuaciones diferenciales lineales, ordinarias de orden dos que adem'as dependen de un par'ametro $\lambda$, es decir dos problemas tipo \emph{Sturm-Liouville}, sin embargo, es necesario imponer \emph{condiciones de frontera}, es decir, buscamos $\phi:\om\subset\re\to\re$ que cumpla la ecuaci'on \ref{edp-lin-red-2}, adem'as, la fontera de $\om$, $\partial\om$ es una curva $\mathcal{C}^{1}$ por tramos parametrizada por $\sigma:I\to\partial\om$, $\sigma(s)=(x(s),y(s))$ con vector normal $\hat{n}$, entonces buscamos que la funci'on $\phi$ cumla;
\begin{equation}
  \alpha\phi(x(s),y(s))+\beta\dfrac{\partial\phi}{\partial \hat{n}}(x(s),y(s))=0.
\end{equation}
Donde, en la ecuaci'on anterior tenemos la derivada normal $\partial\phi/\partial\hat{n}=\nabla\phi\cdot\hat{n}$. Es decir, por lo tanto el con m'etodo de Bernoulli, resolviendo \emph{los problemas de Sturm-Liouville} derivados de la ecuaci'on original, tenemos una familia de soluciones
\[
  \phi_{\lambda}(x,y)=\varphi_{\lambda}(x)\psi_{\lambda}(y).
\]
Ahora buscamos, a partir de dicha \emph{familia de soluciones}, obtener el espacio de soluciones generales. En los casos que hemos dicutido hasta ahorita, 'esta es una familia \emph{numerable} de soluciones y por lo tanto una soluci'on general por linealidad deber'ia ser algo del estilo
\[
  \phi(x,y)=\sum_{n=0}^{\infty}A_{n}\phi_{\lambda_{n}}(x,y)=\sum_{n=0}^{\infty}A_{n}\varphi_{\lambda_{n}}(x)\psi_{\lambda_{n}}(y).
\]
Sin embargo es posible que dicha familia de soluciones sea \emph{no numerable}, sobretodo en mayores dimensiones, en cuyo caso, por el \emph{teorema espectral}, la soluci'on general se escribe de la forma
\[
  \phi(x,y)=\int A(\lambda)\phi_{\lambda}(x,y)\,\mu(\lambda)=\int A(\lambda)\varphi_{\lambda}(x)\psi_{\lambda}(y)\,\mu(\lambda).
\]
Donde $\mu$ es la \emph{medida espectral}, sin embargo nosotros s'olo consideraremnos el caso en el que tengamos espectro \emph{discreto}, con esto en mente el siguiente teorema nos permite resolver esto en el caso \emph{discreto}

\subsection{Las funciones de Green como superposici'on de funciones propias}
\noindent Una aplicacion a lo que hemos visto anteriormente es la posibidad de calcular la funcion de Green de un operador diferencial lineal ordinario de orden dos. Supongamos que $\mathcal{L}$ es un operador diferencial lineal ordinario de orden dos,
en el cap'itulo anterior logramos resolver las ecuaciones de tipo con ciertos valores de frontera de tipo \ref{SL-fron} en el intervalos $[a,b]$
\[
  \mathcal{L}[\psi_{n}]=\lambda_{n}\rho(x)\psi_{n}(x).
\]
Las cuales nos daban una \emph{descomposici'on espectral} del operador $\mathcal{L}$, es decir obtenemos la posibilidad de expresar cualquier funci'on cuadrado integrable $f$ por medio de las funciones propias $\phi_{n}$ con valores propios $\lambda_{n}$, en particular, si se quiere resolver la \emph{ecuaci'on no homogenea}
\[
  \mathcal{L}[\phi](x)=f(x),
\]
entonces podemos expresar a la soluci'on $\phi$ como una \emph{superposici'on de funciones propias}
\[
  \phi(x)=\sum_{n=0}^{\infty}\gamma_{n}\psi_{n}(x).
\]
Donde $\gamma_{n}\in\co$, por lo tanto al aplicar $\mathcal{L}$ obtenemos
\[
  f(x)=\mathcal{L}[\phi](x)=\mathcal{L}\left[\sum_{n=0}^{\infty}\gamma_{n}\phi\psi_{n}\right](x)=
  \sum_{n=0}^{\infty}\gamma_{n}\lambda_{n}\rho(x)\psi_{n}(x).
\]
Ahora al aplicar el poducto interno con $\psi_{k}$ obtenemos
\[
  \braket{\psi_{k}|f}=\int_{a}^{b}\overline{\psi_{k}}(\xi)f(\xi)\,d\xi=
  \sum_{n=0}^{\infty}\int_{a}^{b}\gamma_{n}\lambda_{n}\overline{\psi_{k}(\xi)}\psi_{n}(\xi)\rho(\xi)\,d\xi.
\]
Por la ortogonormalidad de la base $\{\psi_{n}\}_{n\in\nat}$, todas las integrales se anulan excepto cuando $n=k$, adem'as $\|\psi_{k}(x)\|_{\rho}=1$, donde $\|\cdot\|_{\rho}$ es la norma inducida por el \emph{producto interno modificado}, as'i podemos despejar $\gamma_{k}$ para obtener
\[
    \gamma_{n}=\frac{1}{\lambda_{n}}\int_{a}^{b}\overline{\psi_{k}(\xi)}f(x)\,d\xi=\frac{1}{\lambda_{n}}\braket{\psi_{k}|f}.
\]
Por lo tanto expresamos la solucion como (podemos meter la serie a la intregral por convergencia uniforme como ya vimos)
\begin{equation}\label{Green1}
  \psi(x)=\int_{a}^{b}\left(\sum_{n=0}^{\infty}\frac{1}{\lambda_{n}}\overline{\psi_{n}(\xi)}\psi(x)\right)f(\xi)\,d\xi.
\end{equation}
Esto implica que podemos expresar a la funci'on de Green como
\begin{equation}\label{Green2}
  G(x,\xi)=\sum_{n=0}^{\infty}\frac{1}{\lambda_{n}}\overline{\psi_{n}(\xi)}\psi_{n}(x).
\end{equation}
Esto es porque la ecuaci'on \ref{Green1} implica que la serie anterior define un inegral tipo Fredholm $\hat{T}$ tal que $\hat{T}=\mathcal{L}^{-1}$ y por unicidad del operador inverso, la ecuaci'on \ref{Green2} es v'alida \emph{casi donde quiera}.

\obs Podemos generalizar el caso anterior cuando tenemos una ecuacion del tipo
\begin{equation}\label{eq-ord2}
  \mathcal{L}[\phi](x)-\mu\rho(x)\phi(x)=f(x)
\end{equation}
Donde $\mathcal{L}$ es un operador diferencial lineal ordinario de orden dos hermitiano (Strum-Liouville) con valores propios $\{\lambda_{n}\}_{n\in\nat}$ y funciones propias $\{\psi_{n}\}_{n\in\nat}$, entonces representamos a $f$ como su \emph{serie de Fourier generalizada}
\begin{equation}\label{fuc-ev}  f(x)=\sum_{n=0}^{\infty}\braket{\psi_{n}|f}_{\rho}\psi_{n}=\int_{a}^{b}f(\xi)\rho(\xi)\left(\sum_{n=0}^{\infty}\overline{\psi_{n}(\xi)}\psi_{n}(x)\right)\,d\xi
\end{equation}
Ahora como esta ecuación es válida para cuaquier función y para todo $x\in[a,b]$ sin embargo eso implica que la expresión
\begin{equation}\label{dirac-delta0}
  \rho(\xi)\left(\sum_{n=0}^{\infty}\overline{\psi_{n}(\xi)}\psi_{n}(x)\right)
\end{equation}
es una función que al multiplicar por cualquier $f$ e integrar, obtenemos su valor $f(x)$ es decir la expresión \ref{dirac-delta0}, en términos de funcionales lineales, es un representante del funcional evaluación en un punto, es decir $f\mapsto f(x)$. Veremos luego que es \emph{imposible} considerando \emph{funciones tradicionales}, lo que sucede aqui es que la expresión \ref{dirac-delta0} es una \emph{función} generalizada y de hecho es la conocida como la \emph{delta de Dirac} $\delta(\xi-x)$ la cual es una ``función'' cuyos valores son $0$ en todos los puntos, excepto en $\{x=\xi\}$ donde toma el valor ``infinito'' y esto es lo que permite que la ecuación \ref{fuc-ev} sea válida para toda $f$ y $x$. Más aún esto implica la siguiente simetía (la cual veremos tanbién posteriormente que relaciona a la fución de Green con la delta de Dirac)
\[
  \rho(\xi)\left(\sum_{n=0}^{\infty}\overline{\psi_{n}(\xi)}\psi_{n}(x)\right)=\delta(\xi-x)=\delta(x-\xi)=  \rho(x)\left(\sum_{n=0}^{\infty}\overline{\psi_{n}(\xi)}\psi_{n}(x)\right).
\]
El hecho de que el operador $\mathcal{L}$ sea herminiano permite la simtería en términos del conjugado en la ecuación anterior. Entonces usando esto en \ref{fuc-ev} obtenemos

\begin{equation}
  f(x)=\int_{a}^{b}f(\xi)\rho(\xi)\left(\sum_{n=0}^{\infty}\overline{\psi_{n}(\xi)}\psi_{n}(x)\right)\,d\xi=\rho(x)\sum_{n=0}^{\infty}\braket{\psi_{n}|f}\psi_{n}(x)
\end{equation}
Entonces si expresamos a $\phi$ como su series de Fourier generalizada $\phi=\sum_{n\in\nat}c_{n}\psi_{n}$, entonces si sustituimos en la ecuación original \ref{eq-ord2}, para obtener
\begin{equation}
\rho(x)\sum_{n=0}^{\infty}(\lambda_{n}-\mu)c_{n}\psi_{n}(x)=\rho(x)\sum_{n=0}^{\infty}\braket{\psi_{n}|f}\psi_{n}(x).
\end{equation}
Lo cual implica que
\[
  c_{n}=\frac{\braket{\psi_{n}|f}}{\lambda_{n}-\mu},
\]
entonces
\[ \phi(x)=\sum_{n=0}^{\infty}c_{n}\psi_{n}(x)=\sum_{n=0}^{\infty}\frac{\braket{\psi_{n}|f}}{\lambda_{n}-\mu}\psi_{n}(x)=
  \int_{a}^{b}\left(\sum_{n=0}^{\infty}\frac{\overline{\psi_{n}(\xi)}\psi_{n}(x)}{\lambda_{n}-\mu}\right)f(\xi)\,d\xi.
\]
Por lo tanto, esto implica que
\[
  G(x,\xi)=\sum_{n=0}^{\infty}\frac{\overline{\psi_{n}(\xi)}\psi_{n}(x)}{\lambda_{n}-\mu}
\]
Cuando el espectro es continua se generaliza a
\[
  G(x,\xi)=\int_{0}^{\infty}\frac{\overline{\psi_{\nu}(\xi)}\psi_{\nu}(x)}{\lambda_{\nu}-\mu}\,d\sigma(\nu),
\]
donde $\sigma$ es la \emph{medida espectral.}

\eje Encuentre la función de Green para el siguiente operador con condiciones de frontera
\[
  y''+\frac{1}{4}y=f(x)\quad y(0)=y(\pi)=0.
\]
Primero hacemos su \emph{descomposicion espectral}
\[
  \psi''+\left(\frac{1}{4}-\lambda\right)\psi=0\quad \psi(0)=\psi(\pi)=0,
\]
entonces
\[
  \psi(x)=A\sin\left(\sqrt{\frac{1}{4}-\lambda}\right)x+B\cos\left(\sqrt{\frac{1}{4}-\lambda}\right)x.
\]
    Ahora, las condiciones de frontera implican que
\[
  \psi_{n}(x)=\sqrt{\frac{2}{\pi}}\sin(nx)\quad\lambda_{n}=\frac{1}{4}-n^{2}\quad n\in\nat.
\]
Los cuales sabemos que son las soluciones \emph{ortonormales}, entonces la fuinción de Green se calcula facilmente como
\[
  G(x,\xi)=\frac{2}{\pi}\sum_{n=0}^{\infty}\frac{\sin(nx)\sin(n\xi)}{\frac{1}{4}-n^{2}}.
\]
\exe Calcule las soluciones al problema anterior si
\begin{itemize}
  \item $f(x)=\sin(2x)$
  \item $f(x)=x/2$
\end{itemize}

\section{La Ecuación de Laplace}









\section{La Ecuación de Calor}













\section{La ecuación de Onda}
\subsection{Método de Frobenius}
\noindent Cuando se tiene una ecuación diferencial de la forma
\[
  \ddot{w}+p(z)\dot{w}+q(z)w=0,
\]
en donde cero es un punto singular regular se puede obtener una solución en serie de potencias. El método consiste en proponer como solución a una serie de la forma
\[
  w(z)=\sum_{i=0}^{\infty}a_{k}z^{k+r},\quad r\geq2.
\]
Se procede a derivar y a sustituir en la ecuación diferencial y de ahí se extrae el coeficiente de la menor potencia de $z$, con esto tenemos la siguiente definición.
\begin{def.}\label{d1.2} % Definición 1.2
  La ecuación indicial es el coeficiente, igualado a cero, que acompaña a la menor potencia en la serie infinita.
\end{def.}
Ésta ecuación merece su definición debido a que nos permite extraer, últimamente, dos soluciones linealmente independientes siempre que la diferencia entre las raíces no sea un entero, en este caso se puede recurrir al método de variación de parámetros (ver~\cite[pp. 137-138]{laura1}). Con esto, obtenemos los coeficientes de la ecuación diferencial uno a uno, otorgándonos la libertad de elegir al primero a nuestra conveniencia.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ----------- Old draft ------------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent Consideremos la ecuación diferencial $\ddot{w}+p(t)\dot{w}+q(t)w=0$ con ~\cite{laura1}
\[
  p(t)=\sum_{i=0}^{\infty}b_{i}t^{i-1},\quad\text{ y }\quad q(t)=\sum_{i=0}^{\infty}c_{i}t^{i-2}.
\]
Procedemos a proponer una solución en series de potencias $w(t)=\sum_{n=0}^{\infty}a_{n}t^{n+r}$. Sustituyendo las derivadas en nuestra ecuación, multiplicando antes por $t^{2}$, obtenemos
\begin{align*}
  &t^{2}\ddot{w}+t^{2}p(t)\dot{w}+t^{2}q(t)w\\
  &=\sum_{n=0}^{\infty}(n+r)(n+r-1)a_{n}t^{n+r}+p(t)\sum_{n=0}^{\infty}(n+r)a_{n}t^{n+r+1}+q(t)\sum_{n=0}^{\infty}a_{n}t^{n+r+2}\\
  &=\sum_{n=0}^{\infty}(n+r)(n+r-1)a_{n}t^{n+r}+\hat{p}(t)\sum_{n=0}^{\infty}(n+r)a_{n}t^{n+r}+\hat{q}(t)\sum_{n=0}^{\infty}a_{n}t^{n+r}\\
  &=\sum_{n=0}^{\infty}\left[(n+r)(n+r-1)+\hat{p}(t)(n+r)+\hat{q}(t)\right]a_{n}t^{n+r}.
\end{align*}
En donde $\hat{p}$ y $\hat{q}$ son de la forma $\sum$\footnote{singularidad removible?}. Ahora, igualando los coeficientes a 0 tenemos, para $n=0$, que $[r(r-1)+b_{0}r+c_{0}]a_{0}=0$, esto es
\[
  r^{2}+(b_{0}-1)r+c_{0}=0.
\]
Esta ecuación nos permite, por medio de sus raíces, obtener una solución determinando el primer coeficiente y consiguiendo los demás a partir de éste. Por este motivo, se amerita la siguiente definición.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ------- End Old Frobenius --------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------- Old old frobenius part ---------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
El método de Frobenius, nombrado en honor al matemático Ferdinand Georg Frobenius, es una manera de encontrar una solución, en forma de una serie de potencias infinita, de una ecuación diferencial ordinaria de segundo orden con coeficientes
\[
  z^{2}\,\ddot{u}(z)+z\,p(z)\,\dot{u}(z)+q(z)\,u(z)=0,
\]
en la vecindad de un punto singular regular $z_{0}$.\\
\indent Más puntualmente, si $z_{0}=0$, buscamos una solución en forma de serie de potencias
\[
  u(z)=z^{r}\sum_{k=0}^{\infty}a_{k}z^{k},\quad a_{0}\neq0.
\]
Derivando,
\[
  \dot{u}(z)=\sum_{k=0}^{\infty}(k+r)a_{k}z^{k+r-1},
\]
y
\[
  \ddot{u}(z)=\sum_{k=0}^{\infty}(k+r)(k+r-1)a_{k}z^{k+r-2}.
\]
Sustituyendo ahora en la ecuación orignal,
\begin{align*}
  &z^{2}\sum_{k=0}^{\infty}(k+r)(k+r-1)a_{k}z^{k+r-2}+zp(z)\sum_{k=0}^{\infty}(k+r)a_{k}z^{k+r-1}+q(z)\sum_{k=0}^{\infty}a_{k}z^{k+r}\\
  &=\sum_{k=0}^{\infty}(k+r)(k+r-1)a_{k}z^{k+r}+p(z)\sum_{k=0}^{\infty}(k+r)a_{k}z^{k+r}+q(z)\sum_{k=0}^{\infty}a_{k}z^{k+r}\\
  &=\sum_{k=0}^{\infty}\left[(k+r-1)(k+r)a_{k}z^{k+r}+p(z)(k+r)a_{k}z^{k+r}+q(z)a_{k}z^{k+r}\right]\\
  &=\sum_{k=0}^{\infty}\left[(k+r-1)(k+r)+p(z)(k+r)+q(z)\right]a_{k}z^{k+r}\\
  &=[r(r-1)+p(z)r+q(z)]a_{0}z^{r}+\sum_{k=1}^{\infty}[(k+r-1)(k+r)+p(z)(k+r)+q(z)]a_{k}z^{k+r}=0.
\end{align*}
La expresión $r(r-1)+p(0)\,r+q(0)=I(r)$ es conocida como la \textit{ecuación indicial}, que es cuadrática en $r$. De forma más concisa, esto lo vemos en la siguiente definición.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
-------- Definición --------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{def.}\label{d1.2} % Definición 1.2
% La ecuación indicial es el coeficiente que acompaña a la menor potencia en la serie infinita.
\end{def.}
En nuestro ejemplo, este es el $r$-ésimo coeficiente, pero es posible que el exponente más pequeño sea $r-2$, $r-1$ o algo más, dependiendo de la ecuación diferencial dada.\\
\indent Lo importante es empezar en el índice de mismo valor, que en nuestro ejemplo es $k=1$; uno puede tener expresiones complicadas, sin embargo, al encontrar las soluciones de la ecuacion indicial, la atención está dirigida sólo hacia el coeficiente de la menor potencia de $z$.\\
\indent Utilizando esto, la expresión general para los coeficentes de $z^{k+r}$ está dada por
\[
  I(k+r)a_{k}+\sum_{j=0}^{k-1}\frac{(j-r)p^{k-j}(0)+q^{k-j}(0)}{(k-j)!}a_{j}.
\]
\indent Estos coeficientes deben ser cero, dado que deben ser soluciones de la ecuación diferencial, así
\begin{align*}
  I(k+r)a_{k}+\sum_{j=0}^{k-1}\frac{(j-r)p^{k-j}(0)+q^{k-j}(0)}{(k-j)!}a_{j}&=0\\
  \sum_{j=0}^{k-1}\frac{(j-r)p^{k-j}(0)+q^{k-j}(0)}{(k-j)!}a_{j}&=-I(k+r)a_{k}\\
  \frac{1}{-I(k+r)}\sum_{j=0}^{k-1}\frac{(j-r)p^{k-j}(0)+q^{k-j}(0)}{(k-j)!}a_{j}&=a_{k}.
\end{align*}
\indent La solución en series con $a_{k}$,
\[
  U_{r}(z)=\sum_{k=0}^{\infty}a_{k}z^{k+r},
\]
satisface
\[
  z^{2}\ddot{U}_{r}(z)+zp(z)\dot{U}_{r}(z)+q(z)U_{r}(z)=I(r)z^{r}.
\]
\indent Si escogemos una de las soluciones a la ecuación indicial para $r$ en $U_{r}(z)$, obtenemos una solución de la ecuación diferencial. Si la diferencia entre las raíces no es entero, obtenemos otra más, linealmente independiente de la solución asociada a la primera solución.\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%---------- Sección ---------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Funciones de Bessel de primer tipo}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------- Definición --------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\noindent~\cite{epelde} Las funciones de Bessel son aquellas que son solución de un tipo de ecuación diferencial, como vemos a continuación.
\begin{def.}\label{d1.3} % Definición 1.3
  Sea $\nu\in\mathbb{C}$. La ecuación diferencial
  \begin{equation}
    \label{eq1.5}
    z^{2}\frac{d^{2}w}{dz^{2}}+z\frac{dw}{dz}+(z^{2}-\nu^{2})w=0,
  \end{equation}
  es conocida como ecuación de Bessel de orden $\nu$.
\end{def.}
Para encontrar soluciones de este tipo de ecuaciones utilizamos el método de Frobenius, el cual consiste en contrar soluciones de la forma
\[
  \sum_{r=0}^{\infty}a_{r}z^{\alpha+r},\quad a_{0}\neq0,
\]
en donde tenemos que determinar una constante $\alpha$ y los coeficientes $a_{j}$, para toda $j\in\mathbb{N}\cup\{0\}$. Las primera y segunda derivadas de $w$ con respecto a $z$ están dadas por
\[
  \frac{dw}{dz}=\sum_{r=0}^{\infty}a_{r}(\alpha+r)z^{\alpha+r-1},\quad\frac{d^{2}w}{dz^{2}}=\sum_{r=0}^{\infty}a_{r}(\alpha+r)(\alpha+r-1)z^{\alpha+r-2}.
\]
Ahora, sustituyendo en la ecuación~\eqref{eq1.5},
\begin{align*}
  z^{2}\sum_{r=0}^{\infty}a_{r}(\alpha+r)(\alpha+r-1)z^{\alpha+r-2}+z\sum_{r=0}^{\infty}a_{r}(\alpha+r)z^{\alpha+r-1}+(z^{2}-\nu^{2})\sum_{r=0}^{\infty}a_{r}z^{\alpha+r}&=0\\
  \sum_{r=0}^{\infty}a_{r}(\alpha+r)(\alpha+r-1)z^{\alpha+r}+\sum_{r=0}^{\infty}a_{r}(\alpha+r)z^{\alpha+r}+\sum_{r=0}^{\infty}a_{r}\nu^{2}z^{\alpha+r}+\sum_{r=0}^{\infty}a_{r}z^{\alpha+r+2}&=0\\
  \sum_{r=0}^{\infty}a_{r}(\alpha+r)(\alpha+r-1)z^{\alpha+r}+\sum_{r=0}^{\infty}a_{r}(\alpha+r-\nu^{2})z^{\alpha+r}+\sum_{r=0}^{\infty}a_{r}z^{\alpha+r+2}&=0\\
  \sum_{r=0}^{\infty}\big((\alpha+r)(\alpha+r-1)+(\alpha+r)-\nu^{2}\big)a_{r}z^{\alpha+r}+\sum_{r=2}^{\infty}a_{r-2}z^{\alpha+r}&=0\\
  \sum_{r=0}^{\infty}\big((\alpha+r)(\alpha+r-1+1)-\nu^{2}\big)a_{r}z^{\alpha+r}+\sum_{r=2}^{\infty}a_{r-2}z^{\alpha+r}&=0\\
  \sum_{r=0}^{\infty}\big((\alpha+r)^{2}-\nu^{2}\big)a_{r}z^{\alpha+r}+\sum_{r=2}^{\infty}a_{r-2}z^{\alpha+r}&=0.
\end{align*}
De esto, tenemos que todos los coeficientes que acompañana a las potencias de $z$ deben ser cero, es decir, se tiene lo siguiente
Primero, notemos que el primer término de la serie está dado por
\[
  (\alpha^{2}-\nu^{2})a_{0}z^{\alpha}=0,
\]
es decir, $(\alpha^{2}-\nu^{2})a_{0}=0$.\\
El segundo término de la serie es
\[
  \big((\alpha+1)^{2}-\nu^{2}\big)a_{1}z^{\alpha+1},
\]
o bien, $\big((\alpha+1)^{2}-\nu^{2}\big)a_{1}=0$.\\
Y para los términos cuando $r\geq2$, dado que ya empieza a correr el índice en la segunda serie, obtenemos que
\[
  \big((\alpha)+r)^{2}-\nu^{2}\big)a_{r}z^{\alpha+r}+a_{r-2}z^{\alpha+r}.
\]
Es decir, $\big((\alpha)+r)^{2}-\nu^{2}\big)a_{r}+a_{r-2}=0$. En resumen,
\begin{align*}
  &(\alpha^{2}-\nu^{2})a_{0}=0,\\
  &\big((\alpha+1)^{2}-\nu^{2}\big)a_{1}=0,\\
  &\big((\alpha+r)^{2}-\nu^{2}\big)a_{r}+a_{r-2}=0,\,\text{ para toda }r\geq2.\\
\end{align*}
Recordemos que $a_{0}\neq0$, por lo que tenemos que $\alpha=\pm\nu$; escogiendo $\alpha=\nu$, obtenemos que las otras dos ecuaciones se convierten en
\[
  (2\nu+1)a_{1}=0
\]
y
\[
  r(2\nu+r)a_{r}+a_{r-2}=0\,\,\text{ para toda }r\geq2.
\]
Con esto,
\[
  a_{1}=0,\quad\,a_{r}=-\frac{a_{r-2}}{r(2\nu+r)},
\]
siempre que $\nu\notin\mathbb{Z}^{-}$, pues de no ser así, el denominador se anularía para alguna $r\geq2$.\\
Así,
\begin{align*}
  a_{2}&=-\frac{a_{0}}{2^{2}(\nu+1)}\\
  a_{3}&=-\frac{a_{1}}{3(2\nu+3)}=0\\
  a_{4}&=-\frac{a_{2}}{2^{2}(\nu+2)}\\
  a_{5}&=-\frac{a_{3}}{5(2\nu+5)}=0\\
       &\vdots
\end{align*}
observamos que todo los coeficientes con índice impar son cero, mientras los pares están dados por la siguiente fórmula de recurrencia
\[
  a_{2r}=-\frac{a_{2r-2}}{2^{2}r(\nu+r)},\,\,r\in\mathbb{N}.
\]
Ahora,
\begin{align*}
  a_{2}&=-\frac{a_{0}}{2^{2}(\nu+1)}\\
  a_{4}&=-\frac{a_{2}}{2^{2}\cdotp 2(\nu+2)}=\frac{a_{0}}{2^{4}\cdotp 2(\nu+1)(\nu+2)}\\
  a_{6}&=-\frac{-a_{4}}{2^{2}\cdotp 3(nu+3)}=-\frac{a_{0}}{2^{6}\cdotp 3!(\nu+1)(\nu+2)(\nu+3)}\\
       &\vdots\\
  a_{2r}&=\frac{(-1)^{r}a_{0}}{2^{2r}\cdotp r!\prod_{k=1}^{r}(\nu+k)},\quad\text{ para todo }r\in\mathbb{N}.
\end{align*}
Teniendo en cuenta que podemos escoger $a_{0}$, lo escogemos como sigue
\[
  a_{0}=\frac{1}{2^{\nu}\,\Gamma(\nu+1)}.
\]
Estamos en condiciones de dar una solución a la ecuación~\eqref{eq1.5}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------- Definición --------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{def.}
  Sea $\nu\in\mathbb{C}$ tal que $2\nu$ no sea un entero negativo. Entonces
  \begin{equation}
    \label{eq1.6}
    J_{\nu}(z)=\sum_{r=0}^{\infty}\frac{(-1)^{r}(z/2)^{\nu+2r}}{r!\,\Gamma(\nu+r-1)},
  \end{equation}
  es llamada \textit{función de Bessel del primer tipo de orden $\nu$ y argumento $z$}.\\
  El mismo proceso puede ser aplicado para $\alpha=-\nu$. Ahora tenemos
  \begin{equation}
    \label{eq1.7}
    J_{-\nu}(z)=\sum_{r=0}^{\infty}\frac{(-1)^{r}(z/2)^{-\nu+2r}}{r!\,\Gamma(-\nu+r-1)},
  \end{equation}
  siempre que $2\nu$ no sea un entero positivo.
\end{def.}
Para trabajar con estas expresiones, es conveniente que las series~\eqref{eq1.6} y~\eqref{eq1.7} sean absolutamente convergentes, esto se muestra en el siguiente lema.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------- Lema -----------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{lema}\label{l1.2} % Lema 1.2
  Las series que definen las funciones de Bessel del primer tipo de orden $\nu$ y $-\nu$ son absolutamente convergentes para toda $z\neq0$.
\end{lema}
\obs
  Dado que las series \eqref{eq2.2} y \eqref{eq2.3} son absolutamente convergentes para toda $z\neq0$, podemos diferenciarlas término a término.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------- Proposición -------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{prop}\label{p1.5} % Proposición 1.5
  Si $\nu\in\mathbb{C}\backslash\{k/2\,|\,k\in\mathbb{Z}\}$, las funciones de Bessel del primer tipo $J_{\nu}$ y $J_{-\nu}$ son linealmente independientes. En tal caso, para toda solución $w$ de~\eqref{eq1.5}, existen $A,B\in\mathbb{C}$ tales que
  \[
    w(z)=A\,J_{\nu}(z)+B\,J_{-\nu}(z).
  \]
\end{prop}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%---------- Sección ---------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Funciones de Bessel de segundo y tercer tipo}
\noindent Vimos que $J_{\nu}(z)$ y $J_{-\nu}(z)$ son linealmente independientes cuando $\nu$ no es un entero. Ahora buscamos una solución a la ecuación de Bessel independiente de $J_{\nu}$ cuando $\nu$ sea un entero.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------- Definición --------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{def.}\label{d1.5} % Definición 1.5
  Sea $\nu\in\mathbb{C}$ constante. Entonces
  \begin{equation}
    \label{eq1.8}
    Y_{\nu}(z)=\lim_{\alpha\to\nu}\frac{(\cos\,\alpha\pi)J_{\alpha}(z)-J_{-\alpha}(z)}{\sen\,\alpha\pi},
  \end{equation}
  es llamada \textit{función de Bessel de segundo tipo de orden $\nu$ y argumento $z$}.
\end{def.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------- Observación -------%
%%%%%%%%%%%%%%%%%%%%%%%%
\obs% Observación 1.1
  Cuando $\nu$ no es un entero, el límite es obtenido sustituyendo y
  \[
    Y_{\nu}(z)=\frac{(\cos\,\nu\pi)J_{\nu}(z)-J_{-\nu}(z)}{\sen\,\nu\pi}.
  \]
  Dado que $Y_{\nu}$ es una combinación lineal de las soluciones de~\eqref{eq1.5}, también es solución.\\
 Sin embargo, cuando $\nu=n\in\mathbb{Z}$, la expresión de arriba toma la forma $(0/0)$, y tomamos el límite.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------- Proposición -------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{prop}\label{p1.6)} % Proposición 1.6
  Para todo entero $n$, la función de Bessel de segundo orden $Y_{n}$ es una solución de la ecuación de Bessel, y es linealmente independiente de $J_{n}$.
\end{prop}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%--------- Corlario --------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{cor}\label{c1.1} % Corlario 1.1
  La solución general de la ecuación de Bessel~\eqref{eq1.5} de orden $\nu\in\mathbb{C}$ es
  \[
    w(z)=aJ_{\nu}(z)+bY_{\nu}(z),\,\,a,b\in\mathbb{C}.
  \]
\end{cor}
En algunas ocasiones, es interesante expresar soluciones de la ecuación de Bessel en maneras distintas. Por lo tanto, definimos funciones de Bessel del tercer tipo en términos de $J_{\nu}(z)$ y $Y_{\nu}(z)$.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------- Definición --------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{def.}\label{d1.6} % Definición 1.6
  Sea $\nu\in\mathbb{C}$ constante, entonces
  \begin{align}
    H_{\nu}^{(1)}(z)&=J_{\nu}(z)+iY_{\nu}(z),\label{eq1.9}\\
    H_{\nu}^{(2)}(z)&=J_{\nu}(z)-iY_{\nu}(z)\label{eq1.10}
  \end{align}
  son llamadas \textit{funciones de Hankel} o \textit{funciones de Bessel del tercer tipo de órden $\nu$}.
\end{def.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------- Proposición -------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{prop}\label{p1.7} % Proposición 1.7
  Dada una constante $\nu\in\mathbb{C}$, las funciones de Hankel de orden $\nu$ son linealmente independientes y la solución general de~\eqref{eq1.5} puede ser expresada como
  \[
    w(z)=aH_{\nu}^{(1)}(z)+bH_{\nu}^{(2)}(z),\,\,a,b\in\mathbb{C}.
  \]
\end{prop}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%---------- Sección ---------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Propiedades de las funciones de Bessel}
\noindent En seguida enunciaremos algunas propiedades de las funciones de Bessel.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------- Proposición -------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{prop}\label{p1.8} % Proposición 1.8
  Sea $\nu\in\mathbb{C}$. Entonces,
  \begin{align}
    J_{\nu+1}(z)&=\frac{\nu}{z}J_{\nu}(z)-J'_{\nu}(z),\label{eq1.11},\\
    J_{\nu-1}(z)&=\frac{\nu}{z}J_{\nu}(z)+J'_{\nu}(z),\label{eq1.12}.
  \end{align}
\end{prop}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%--------- Corlario --------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{cor}\label{c.12} % Corlario 1.2
  Si $\nu\in\mathbb{C}$,
  \begin{align}
    J_{\nu-1}(z)+J_{\nu+1}(z)&=\frac{2\nu}{z}J_{\nu}(z),\label{eq1.13}\\
    J_{\nu-1}(z)-J_{\nu+1}(z)&=2J'_{\nu}(z),\label{eq1.14}
  \end{align}
\end{cor}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%---------- Sección ---------%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
